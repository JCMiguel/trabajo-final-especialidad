%%%%%%%%% SECTION %%%%%%%%%
\subsection{Anexo PI2: Datos de recuento} \label{appendix:es/rpi2_datos}

Los datos utilizados para la síntesis de resultados a la Pregunta de Investigación 2 se presentan en la Tabla \ref{tabla:es/rpi2_datos}

%\begin{longtable}{|| m{8em} m{5em} m{19em} ||}
{
\scriptsize
\begin{longtable}{|| p{.20\textwidth} p{.16\textwidth} p{.54\textwidth} ||}

\hline
    \textbf{Autores del Estudio Primario}		& \textbf{Postura reportada}	& \textbf{Cita textual que lo fundamenta} \\ [0.5ex]
    \hline \hline
    \endhead
% \hline \hline 
    \caption{Posturas reportadas por los autores de los estudios primarios. \label{tabla:es/rpi2_datos}}
    \endfirstfoot
% \hline \hline 
    \caption[]{(Continuación) Posturas reportadas por los autores de los estudios primarios.}
    \endfoot
Verma et al. 						& Colaborativo		& We asked the interviewees about their perceptions regarding the current role and impact of AI in cancer care, and how it might evolve in the future. In particular, how AI-powered technologies will shape their work practices and their relationship with patients \cite{Verma2023}. \\
 \hline
Di Giammarco et al.					& Colaborativo		& The use of three distinguished CAMs, i.e. Grad-CAM, Score-CAM, and FastScore- CAM, united to the index similarity; improves the reliability and the trustworthiness of AI in healthcare. This indicates that while deep learning prediction does not replace human decisions, it does aid in the consultation process during the diagnostic procedure \cite{DiGiammarco2024}. \\
 \hline
Bouderhem et al.					& Colaborativo		& It is necessary to look beyond the hype and assess the pros and cons of AI in healthcare today \cite{Bouderhem2024}. \\
 \hline
Pahud de Mortanges et al.			& Colaborativo		& LLM-based technologies could enable a bidirectional “dialogue” between users and (X)AI systems. In the more or less distant future, such systems may serve as a virtual assistant capable of working as a counselor in clinical scenarios \cite{PahuddeMortanges2024}. \\
 \hline
Lee et al.							& Colaborativo		& Adopting digital pathology can enable pathologists to improve their workflow efficiency, accessibility, and quantitative analysis, advancing biomedical knowledge and research \cite{Lee2024}. \\
 \hline
Lee et al.							& No colaborativo	& (...) we use metrics to compare the performances of explainable AI methods instead of relying on human evaluations \cite{Lee2024}. \\
 \hline
Wang et al.							& No colaborativo	& This results in overworked pathologists, which can lead to higher chances of deficiencies in their routine work and dys- functions of the pathology laboratories with more laboratory errors. (...) It is thus imperative to develop reliable tools for pathological image analysis and CRC detection that can improve clinical efficiency and efficacy without unin- tended human bias during diagnosis \cite{Wang2021}. \\
 \hline
Rösler et al.						& Colaborativo		& As populations age and cancer become more prevalent, more trained personnel are required to care for cancer patients. AI can potentially help to train these experts, although this aspect is still an emerging feld in hematology and oncology \cite{Roesler2023}. \\
 \hline
Zehra et al.						& Colaborativo		& Digital pathology and AI can only be added to routine histopathology workflow. Conventional histopathology cannot be substituted \cite{Zehra2023}. \\
 \hline
Guleria et al.						& No colaborativo	& We suggest deploying deep-learning-based image recognition models, which ofer the potential to improve accuracy of pCLE and histopathology and to recognize patterns that may have eluded human visual analysis. (...) Our work indirectly suggests that these models may achieve similar accuracy as human interpreters, paving the way frst for more direct comparisons of humans and deep learning models and then for increased clinical application of these technologies \cite{Guleria2021}. \\
 \hline
Finzel et al.						& Colaborativo		& They (GNN) provide the means toward transparency and, ideally, could be used in combination with symbolic approaches to generate verbal or language-like explana- tions for increased comprehensibility and better control of the overall system to satisfy the validation and improvement requirements of human-centric AI \cite{Finzel2022}. \\
 \hline
Mohammadi et al.					& Colaborativo		& Modern artificial intelligence (AI)-based systems have the potential to handle vast amounts of data, far in excess of what humans are capable of, and as such have huge potential to assist pathologists in their diagnostic work and allay these pressures \cite{Mohammadi2022}. \\
 \hline
Holzinger et al.					& Colaborativo		& Such (ML) systems are not able to understandthe context, hence cannot reason about interventions and retrospection. However, such approaches needs the guidance of ahuman model similar to the ones used in causality research to answer the question “Why?” \cite{Holzinger2019}. \\
 \hline
Yin et al.							& Colaborativo		& Although the inclusion of pathologists (i.e., human-in-the-loop) in the model development process is very important, there is a need to go beyond interpretable machine learning. To reach a level supporting the pathologists in their daily decision making, another factor that should be taken into account is causability [33], which is measured in terms of effectiveness, efficiency, satisfaction related to causal understanding and its transparency for a user. In other words, it refers to a human understandable model \cite{Yin2020}. \\
 \hline
Sabol et al.						& Colaborativo		& A long list of machine learning approaches to image classification and whole-slide segmentation has been developed to support pathologist in interpreting histopathological images \cite{Sabol2020}. \\
 \hline
Cai et al.							& Colaborativo		& (...) we examine what types of information end-users desire to know about an AI Assistant during onboarding, and relate these needs to the existing medical practices of competence articulation and the seeking of input and second opinions from colleagues \cite{Cai2019}. \\
 \hline
Cai et al.							& No colaborativo	& Within this space, a significant portion of recent research has focused on demonstrating that these models can rival the accuracy of medical experts \cite{Cai2019}. \\
 \hline
Tjoa y Guan							& Colaborativo		& For now, if “interpretable” algorithms are deployed in medical practices, human supervision is still necessary. Interpretability information should be considered nothing more than complementary support for the medical practices before there is a robust way to handle interpretability \cite{Tjoa&Guan2021}. \\
 \hline
Ayorinde et al.						& Colaborativo		& To effectively appraise research and new market tools, clinicians need an awareness of the common problems that arise in AI training and deployment. In parallel, teams developing AI image classiffiers need continual dialogue with clinicians that is centered on the trade-offs that their chosen designs entail; to secure trust, and facilitate a smooth translation to the clinic \cite{Ayorinde2022}. \\
 \hline
Palatnik de Sousa et al.			& Colaborativo		& (...) A pathologist using this XAI methodology as a decision support tool could then apply this approach on every patch where deemed necessary \cite{PalatnikdeSousa2019}. \\
 \hline
Gu et al.							& Colaborativo		& In this work, instead of employing AI to replace pathologists, we adapt AI closely to doctors’ domain knowledge of navigation, enabling them to work collaboratively with AI. Our validation study shows that our human + AI approach is recognized to have a better workflow integration and can help pathologists achieve higher precision and recall on average compared to start-of-the-art AI \cite{Gu2023NaviPath}. \\
 \hline
Gu et al.							& Colaborativo		& (Pathologists) examine its results and evidence accordingly in an explainable manner, and examine the evidence to update the suggested diagnosis \cite{Gu2023XPath}. \\
 \hline
Tschandl et al.						& Colaborativo		& AI-based triage and decision support could assist readers in managing workloads and expanding their performance \cite{Tschandl2020}. \\
 \hline
Tschandl et al.						& No colaborativo	& Most research to date has been predicated on head-to-head comparisons of the diagnostic accuracy of AI-based systems with that of humans \cite{Tschandl2020}. \\
 \hline
Gallo et al.						& No colaborativo	& (...) the authors demonstrate an AI solution that performs at a level equal to pathologists. In some cases, such as detecting Gleason pattern four types of prostate cancer, it even surpasses the pathologists’ detection rate \cite{Gallo2023}. \\
 \hline
Dolezal et al.						& Colaborativo		& Explaining how a model has reached its decision and the level of certainty associated with a prediction can help build clinician trust, which may help foster greater adoption of these tools into clinical practice. Soft- ware that seamlessly integrates explainability and uncertainty quantifcation presents a signifcant advantage in promoting the potential clinical utility of these deep learning tools \cite{Dolezal2024}. \\
 \hline
Vanitha et al.						& Colaborativo		& This step forward (Grad-CAM) is pivotal for the adoption of AI in routine clinical practices, ensuring that AI-sup- ported diagnostics are both interpretable and verifable by expert clinicians \cite{Vanitha2024}. \\
 \hline
Dörrich et al.						& Colaborativo		& Explainable AI techniques help both developers and physicians to better understand AI algorithms, their abilities, and their limitations \cite{Doerrich2023}. \\
 \hline
Tosun et al.						& Colaborativo		& It is critical to emphasize that the purpose of the xAI is not to make a diagnosis independent from the pathologist, but to assist the pathologist in being more accurate and efficient \cite{Tosun2020}. \\
 \hline
Jarrahi et al.						& Colaborativo		& The interoperability challenges lead to accountability issues in high-stake decisions in pathology as human experts (i.e., pathologists) are deemed irreplaceable and must actively participate in decision making. As others noted, historically “human–machine collaborations have performed better than either one alone” in these contexts, and such a partnership requires opening the black box of AI and making results transparent and explainable for different stakeholders \cite{Jarrahi2022}. \\
 \hline
Shahamatdar et al.					& No colaborativo	& DNNs rival expert pathologists at detecting malignant skin lesions, diagnosing diabetic retinopathy and detecting breast cancer. In each of these cases, DNNs learned to solve straightforward but time-consuming tasks that are already within the expert physician’s repertoire. However, there is now a growing number of reports that DNNs can also learn to solve tasks posed on histopathological images that are difficult or impossible for pathologists to do by visual analysis alone \cite{Shahamatdar2024}. \\
 \hline
Praetorius et al.					& No colaborativo	& We envisage IMFSegNet to be a step towards making conventional ordinal-scaled and subjective characterization by a pathologist obsolete in the future. In fact, while artificial intelligence may take over the routine work, the future role of pathologists may be more supervising the automated process \cite{Praetorius2023}. \\
 \hline
Kiehl et al.						& Colaborativo		& Human pathologists are also needed to detect rare pathologies that the algorithms have not been trained on. For the near future, it seems more likely that pathologists using AI will replace those not using it, creating a combination of human and machine intelligence (augmented intelligence). AI-based diagnostic support systems can help avoid decision fatigue and enable the pathologist to do more work. For the longer term, however, emerging technologies will bring significant changes in workflow. These changes will enable machines to perform diagnostic tasks in ways that are very different from how human pathologists operate \cite{Kiehl2022}. \\
 \hline
Kiehl et al.						& No colaborativo	& Will AI replace pathologists? There are some concerns in the specialty about the possible elimination of jobs. The threat of automation may discourage potential trainees from choosing the specialty, thus increasing the growing shortage of pathologists \cite{Kiehl2022}.  \\
 \hline
Ullah et al.						& Colaborativo		& The introduction of LLMs in diagnostic medicine may lead to concerns regarding the professional autonomy and decision-making abilities of healthcare professionals. There is a risk of over-reliance on the model’s suggestions, potentially diminishing critical thinking and independent clinical judgment. Care must be taken to ensure that LLMs serve as a valuable tool to augment the expertise of healthcare professionals rather than replacing their crucial role in the diagnostic process \cite{Ullah2024}. \\
 \hline
Nasir et al.						& Colaborativo		& Risks involve potential misinformation, over-reliance on AI, ethical and legal concerns, and the absence of emotional support. It should be used cautiously to complement human expertise rather than replace it entirely \cite{Nasir2024}. \\
 \hline
Finzel et al.						& Colaborativo		& We believe that providing more human-centered and integrative explanation frameworks will pave the way to beneficial AI transparency and human understanding of and trust in AI \cite{Finzel2024}. \\
\hline

\end{longtable}
}