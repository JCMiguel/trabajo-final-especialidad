%%%%%%%%%%%%%%%%%%%% SECTION %%%%%%%%%%%%%%%%%%%%%%%
\subsection{Aspectos regulatorios}
% En caso de confiar en un algoritmo de AI que brinda un diagnòstico equivocado, ¿quién es responsable bajo la ley?
% Privacidad de datos. Datasets públicos vs historia clínica de los pacientes (privada por default)

Respecto a regulaciones, Tosun et al. [PS3] comentan que a proposed regulation before the European Union would prohibit “automatic processing” unless people are safeguarded. Sostienen que future laws may further restrict AI use in professional practices, which represents a huge challenge to industry.

Por su parte, Dos Santos et al. [PS7] sostienen que los algoritmos de AI deben disponer de estándares regulatorios para testeo y usos en clínicas. Según Tosun et al. [PS3] esto ya es una necesidad reconocida en radiología.

Respecto a la privacidad de los datos, Rösler et al. [PS10] observan que 
se debe contar con an ethical approval and informed consent of the patient prior to the use and evaluation of patient-related data. Añade que, de ser posible, anonymized raw data have to be included from the start of the training process.

% 6-Tosun
% A proposed regulation before the European Union would prohibit “automatic processing” unless people are safeguarded (https://ec.europa.eu/futurium/en/ai-alliance-consultation). People now have a “right to an explanation” concerning algorithm-created decisions that are ased on personal information.
% Future laws may further restrict AI use in professional practices, which represents a huge challenge to industry. Radiologists are already beginning to recognize the need for standards, for physician education, and for AI-specific guidelines in their practice, as exemplified in a draft document issued by The Royal Australian and New Zealand College of Radiologists.38

% 21-dos santos
% 6) Algorithms must meet regulatory standards for testing and use in clinical settings.

% 23-Rösler
%It goes without saying that data in medicine must be securely stored, transferred, and protected from unauthorized access.This raises new issues in the age of artifcial intelligence.Under certain conditions, it is possible to extract raw datafrom an AI network that has been trained on medical dataand then published or sold for further use. In recent years,technological advancements such as diferential privacyand secure multi-party computation have attempted toaddress this problem by introducing noise into the raw dataof the training set or by privacy preserving computationalapproaches. However, in any case, it is critical that if possible, anonymized raw data are included from the start ofthe training process, and that, as is standard in medicine,an ethical approval and informed consent of the patient is available prior to the use and evaluation of patient-related data. (Seastedt et al. 2022)