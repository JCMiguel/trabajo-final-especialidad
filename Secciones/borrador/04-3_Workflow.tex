%%%%%%%%%%%%%%%%%%%% SECTION %%%%%%%%%%%%%%%%%%%%%%%
\subsection{Acomplamiento al flujo de trabajo}
% AI no como reemplazo. AI no reemplaza la histologìa manual

Ayorinde et al. [PS2] postulan que no es necesario lograr un sistema AI perfecto para que pueda ser utilizado en las clínicas. Sostienen, en cambio, que es probable que las herramientas más útiles sean una combinación entre AI models y conjuntos de reglas de trabajo que favorezcan la effective human supervision.

Según Tosun et al. [PS3], la principal función de xAI en patología es promote safety, reliability, and accountability in addressing issues with bias, transparency, safety, and causality. Los autores observan, no obstante, que no hay un consensus on how pathologists should supervise or work with computational pathology systems. Dado que patient safety in pathology is the result of a complex interaction between pathologist, other physicians and laboratory personnel, and computational pathology applications, concluyen que xAI debe ayudar al patólogo a ser más preciso y eficiente en su trabajo.

Jaharri et al. [PS4] postulan que AI/xAI systems employed in medicine present interoperability challenges, dado que estos sistemas a menudo presentan amount of information or in formats that appear indecipherable to physicians. Los autores de este estudio proponen que un expert-in-the-loop AI work system could clarify a mutual workflow between humans and machines.

Por su parte, Verma et al. [PS5] propose that AI can be included in collective decision-making processes in oncology either as a tool or as a member, each of these alternatives generating diferent sets of ethical, societal and technological issues. En base a una entrevista que realizaron a seven physicians working at the Lausanne University Hospital (CHUV), respecto a la autononomía de los AI systems observan un consenso en que no se puede put trust in something that is not trustful or bypass the doctors. Uno de los expertos entrevistados añade además que no se puede confiar en un AI model si no es able to choose which treatment modality works best for this particular patient.


% 4-Ayorinde-AI Renal Histopathology.pdf
% Perfectly accurate and perfectly intelligible systems are not yet a reality, but they are not required; clinically useful tools are likely to blend islands of AI automation with rule-based work lows that improve interpretability of the decision-making process and allow effective human supervision.

% 6-Tosun
% The main goal with xAI for pathology is to provide clear justifications to the user for the automated recommendations made in the diagnostic workflow (Fig. 1). This will promote safety, reliability, and accountability in addressing issues with bias, transparency, safety, and causality.
% In pathology, patient safety is paramount and is the result of a complex interaction between pathologist, other physicians and laboratory personnel, and computer systems including computational pathology applications.
% There is also a lack of consensus on how pathologists should supervise or work with computational pathology systems.
% It is critical to emphasize that the purpose of the xAI is not to make a diagnosis independent from the pathologist, but to assist the pathologist in being more accurate and efficient.

% 7-Jaharri
% These systems do not necessarily relate to the needs and practices of end-users (medical professionals); for example, they may provide a large amount of information or in formats that appear indecipherable to physicians (e.g., the feature–importance vector format).22 The interoperability challenges lead to accountability issues in highstake decisions in pathology as human experts (i.e., pathologists) are deemed irreplaceable and must actively participate in decision making.
% Even explainable AI systems (XAI) currently employed in medical settings present significant interoperability challenges.12 These systems do not necessarily relate to the needs and practices of end-users (medical professionals); for example, they may provide a large amount of information or in formats that appear indecipherable to physicians (e.g., the feature–importance vector format).22
% End-to-end AI systems gloss over the complicated contexts of clinical decision-making in pathology, posing regulatory and pragmatic challenges. Rising evidence suggests even the explainability features recently added to the end-to-end AI system as posthoc interpretations appear ineffective in real-world clinical practices.12 The symbiotic relationship presented here in the form of the expert-in-the-loop AI work system could clarify the unique contributions of both humans and machines in a mutual workflow and raise trust in the application of AI in a pathology setting.

% 10-Verma
% At a more general level, we propose that AI can be included in collective decision-making processes in oncology either instrumentally (as a “tool”) or constitutively (as a “member”), each of these alternatives generating diferent sets of ethical, societal and technological issues to be solved in future research.
% This discrepancy in adoption of AI in clinical settings has been attributed to varied factors, including, poor contextual ft and mismatch with clinical workfows [9, 25]. To address these fundamental problems, calls have been made forHCI and AI communities to establish deep and meaningful collaborations with healthcare domain, and more importantly, healthcare professionals [28, 57, 70, 83].
% In response to our question about responsibility, and who bears it in case of a mistake, P01 answered that “a physician is legally always responsible” and “each hospital protects itself ” (P06). Moreover, basing his argument in human rights and elaborating the patient’s perspective P02 stated that “a patient has the right to be here and to be treated, and we will do our best to provide the maximum attention for medical care”, and as a consequence you cannot “put your trust in something that is not trustful” or “bypass the doctors”. P05 also expressed similar concerns regarding the autonomous use of AI systems on the clinical side: “... from the legal point-of-view and from ethical stand-point, if I am not 100% sure that this [AI model] will be able to independently choose which treatment modality works best for this particular patient – a human being, I will not be able to tell the patient that I trust this model.”


